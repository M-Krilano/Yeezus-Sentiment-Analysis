{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Yeezus Sentiment Analysis - Part 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Up With Kanye West?\n",
    "Ever since I was in middle school I've been a huge Kanye West fan. I'm talking about pink-polo, white sunglasses and backpack Kanye...the old Kanye. I don't want to get tangled into the political drama that's going on with Kanye and his relationship with Trump; however, I am concerned for Kanye's mental health since he publicly stated he's depressed. It's understandable though, he's got a lot going on his plate from being a husband to Kim K, fathering three beautiful children, running his fashion line, and other \"dope shit\". It seemed like he was a lot happier back when he was young and choppin' up beats and interuppting Taylor Swift at award shows...or maybe that's just what I want to believe.\n",
    "\n",
    "### Hypothesis:\n",
    "I hypothesize that Ye was significantly happier and more positive back in his early career than the current yeezy we all know today.\n",
    "\n",
    "#### Side Note:\n",
    "Unfortunately Kanye only joined twitter in 2010 which was after a lot of his big albums, so I decided to take tweets from 2010 to 2012 (before he started dating Kim K) and use that for the \"old_kanye\" data set and use tweets from 2017 to present for the \"current_kanye\" data set \n",
    "\n",
    "#### Update (after extracting all of Ye's tweets):\n",
    "Kanye is Kanye and deletes his tweets all the time so the oldest tweets I can extract are from early April 2018 and one tweet from 2014. So I will just have to run a sentiment analysis on the data I have and won't be able to compare old and new tweets. \n",
    "\n",
    "\n",
    "### Method:\n",
    "1. I'm going to extract Kanye's tweets and insert them in a table in a mysql database\n",
    "    (json, tweepy, mysql_connector)\n",
    "2. Query specific data to make my data set\n",
    "    (pandas, mysql_connector)\n",
    "3. Clean the data\n",
    "    (pandas, nltk, bs4, re)\n",
    "4. Calculate Sentiment Values\n",
    "    (textblob)\n",
    "5. Visualize the data\n",
    "    (wordcloud, sklearn, pyplot, matplotlib)\n",
    "6. Asess the data\n",
    "\n",
    "\n",
    "### Tools:\n",
    "To extract Data from Twitter:\n",
    "- tweepy: twitters API that allows me to grab tweets\n",
    "- json: allows me to change the extract tweets, which comes in \"tweepy.models.ResultSet\", then dumps it into a\n",
    "  json string, then loads it into a list of dictionaries (each dictionary is a tweet containing a Tweet Object)\n",
    "  \n",
    "  \"The Tweet object has a long list of ‚Äòroot-level‚Äô attributes, including fundamental attributes such as 'id',\n",
    "  'created_at', and 'text'. Tweet objects are also the ‚Äòparent‚Äô object to several child objects. Tweet child\n",
    "  objects include user, entities, and extended_entities. Tweets that are geo-tagged will have a place child\n",
    "  object.\"\n",
    "  https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html\n",
    "  \n",
    "To Extract Data from twitter:\n",
    "- tweepy: twitter client authentication and requests to get tweets\n",
    "- json: to transfer tweet objects to dictionary\n",
    "\n",
    "To Store Data:\n",
    "- mysql: allows me to connect to database insert rows of data into my database\n",
    "\n",
    "To Extract Data from mysql:\n",
    "- mysql_connector: allows me to connect and pull data from my database\n",
    "- pandas: to manipulate the data\n",
    "\n",
    "To clean Data:\n",
    "- re: helps me extract meta-characters and patterns (twitter handles, urls, encoded HTML, etc)\n",
    "- bs4: decodes HTML to general text\n",
    "- nltk: tokenizes words\n",
    "\n",
    "\n",
    "To make the analysis I am going to use a few important libraries such as: \n",
    "- NLTK(Natural Language Toolkit): has an array of useful functions for natural language processing. \n",
    "- TextBlob: to help us calculate sentiment\n",
    "- Word Cloud Library: to create some summary visualisations of our tweets\n",
    "\n",
    "\n",
    "\n",
    "#### NLP:\n",
    "Pre-Processing steps in NLP:\n",
    "1. Look at char length of text, plot it, and see if there's anything odd (sanitation)  \n",
    "1. Remove HTML, punctuation, special characters(twitter handlers), and stop words\n",
    "2. Normalisation (stemming)\n",
    "3. Tokenisation.\n",
    "4. Lemmatisation\n",
    "5. TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import json\n",
    "from dateutil import parser\n",
    "\n",
    "from tweepy import API\n",
    "from tweepy import Cursor\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "import nltk\n",
    "\n",
    "from textblob import TextBlob\n",
    "from wordcloud import wordcloud, STOPWORDS\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import twitter_credentials\n",
    "import db_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Connector\n",
    "##### Function: grab_all_tweets()\n",
    "Purpose: Takes in the screen name of the person you'd like to analyze on twitter and returns a dataframe of all the extracted tweets on their timeline.\n",
    "Note: There is a max limit of 200 recent tweets you can grab per request using \"api.user_timeline()\", so i used a while loop and saved the id's of the last extracted tweet and re requested using the oldest tweet id for the \"max_id\" argument. Once all tweets are collected then the json is extracted from the tweet objects which  is then converted to a list of dictionary tweets. Then \"extract_TWeetObjs_db()\" is called to store data. Next \"query_db()\" is called to grab the data from the mysql and returns the dataframe of the tweets.   \n",
    "##### Function: extract_TWeetObjs_db()\n",
    "Purpose: Takes in the array of tweet dictionaries. Loops through each tweet extracting the following attributes: 'id', 'created_at', and 'text'and then calls \"insert_query_db()\" to insert the row of info into the db\n",
    "##### Function: insert_query_db()\n",
    "Purpose: Takes in the attributes('id', 'created_at', text'), connects to the mysql database, and executes the query to INSERT the info.\n",
    "Note: 'id' = VARCHAR, 'created_at' = date, 'text' = text\n",
    "##### Function: query_db()\n",
    "Purpose: Connects to the mysql database, and executes the query to SELECT the info and inputs it into a dataframe.\n",
    "Notes: 'id' = VARCHAR, 'created_at' = date, 'text' = text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mysql_db():\n",
    "    def grab_all_tweets(self, screen_name):\n",
    "    \n",
    "        twitter_client = TwitterClient()\n",
    "        #twitter_analyzer = TwitterAnalyzer()\n",
    "        api = twitter_client.get_twitter_client_api()\n",
    "\n",
    "        #initialize a list to hol all the teets\n",
    "        all_tweets = []\n",
    "        \n",
    "        ## Get request for 200 recent tweets from user's timeline\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "        \n",
    "        ## save most recent tweets\n",
    "        all_tweets.extend(new_tweets)\n",
    "\n",
    "        ## save oldest tweet id\n",
    "        oldest_tweet = all_tweets[-1].id -1\n",
    "    \n",
    "        ## extract all tweets from user\n",
    "        while len(new_tweets) > 0:\n",
    "            print(\"getting tweets before %s\" % (oldest_tweet))\n",
    "            new_tweets = api.user_timeline(screen_name=screen_name, count=200, max_id=oldest_tweet)\n",
    "            \n",
    "            ## save most recent tweets\n",
    "            all_tweets.extend(new_tweets)\n",
    "            ## update the id of oldest tweet\n",
    "            oldest_tweet = all_tweets[-1].id - 1\n",
    "            print(\"...%s tweets downloaded so far\" % (len(all_tweets)))\n",
    "    \n",
    "        ## a string of json containing the info in all of the tweets\n",
    "        status_json = json.dumps([status._json for status in all_tweets])\n",
    "\n",
    "        ## converts string of json to a list of dictionaries, each dictionary is a tweet\n",
    "        status_array = json.loads(status_json)\n",
    "\n",
    "        ## analyzes an array containing dictionaries of tweets\n",
    "        self.extract_TWeetObjs_db(status_array)\n",
    "        df_kanye = self.query_db()\n",
    "        return df_kanye\n",
    "           \n",
    "    def extract_TWeetObjs_db(self, data_array=[]):\n",
    "        try:\n",
    "            # loop through list of dictionary tweets and extract info\n",
    "            for index in range(len(data_array)):\n",
    "                data = data_array[index]\n",
    "               \n",
    "                #username = data['user'][\"screen_name\"]\n",
    "                id = data['id']\n",
    "                #print(id)\n",
    "                #print(type(id))\n",
    "                created_at = time.strftime('%Y-%m-%d', time.strptime(data['created_at'],'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "                tweet = data['text']\n",
    "                # Connect to MySql database\n",
    "                self.insert_query_db(id, created_at, tweet)\n",
    "\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "    \n",
    "    def insert_query_db(self, id, created_at, tweet):\n",
    "        #Connects to MySQL database and inserts twitter data (make sure charset is 'utf8mb4' inorder to insert emojis)\n",
    "        try:\n",
    "            con = mysql.connector.connect(user=db_info.user, password=db_info.pw,\n",
    "                                          host=db_info.host, database=db_info.db_name, auth_plugin=db_info.auth_name, charset = 'utf8mb4')\n",
    "\n",
    "            if con.is_connected():\n",
    "                #Insert twitter data\n",
    "                cursor = con.cursor()\n",
    "                #Insert twitter data\n",
    "                #query = \"INSERT INTO TW_table (tweet_id, created_at, tweet) VALUES (%s, %s, %s)\"\n",
    "                query = \"INSERT INTO TW_table(tweet_id, created_at, tweet) VALUES (%s, %s, %s);\"\n",
    "                cursor.execute(query, (id, created_at, tweet))\n",
    "                con.commit()\n",
    "                #print('DEBUG: Successfully inserted twitter data to db')\n",
    "            else:\n",
    "                print('DEBUG: connect_db : could not connect')\n",
    "\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "\n",
    "        cursor.close()\n",
    "        con.close()\n",
    "        return\n",
    "    \n",
    "    def query_db(self):\n",
    "        #Connects to MySQL database and inserts twitter data (make sure charset is 'utf8mb4' inorder to insert emojis)\n",
    "        try:\n",
    "            con = mysql.connector.connect(user=db_info.user, password=db_info.pw,\n",
    "                                          host=db_info.host, database=db_info.db_name, auth_plugin=db_info.auth_name, charset = 'utf8mb4')\n",
    "\n",
    "            if con.is_connected():\n",
    "                cursor = con.cursor()\n",
    "                query = \"SELECT tweet_id, created_at, tweet FROM `TwitterDB`.`TW_table`;\"\n",
    "                cursor.execute(query)\n",
    "                data = cursor.fetchall()\n",
    "                # store in dataframe\n",
    "                df = pd.DataFrame(data,columns = ['tweet_id', 'date', 'tweet'])\n",
    "                print(\"DEBUG: Successfully queried to df\")\n",
    "            else:\n",
    "                print('DEBUG: connect_db : could not connect')\n",
    "\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "\n",
    "        cursor.close()\n",
    "        con.close()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWITTER CLIENT\n",
    "#### Purpose:\n",
    "Authenticates my credentials for the twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient():\n",
    "    def __init__(self, twitter_user=None):\n",
    "        self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
    "        self.twitter_client = API(self.auth)\n",
    "\n",
    "        self.twitter_user = twitter_user\n",
    "\n",
    "    def get_twitter_client_api(self):\n",
    "        return self.twitter_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWITTER AUTHENTICATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterAuthenticator():\n",
    "    def authenticate_twitter_app(self):\n",
    "        auth = OAuthHandler(twitter_credentials.CONSUMER_KEY,\n",
    "                            twitter_credentials.CONSUMER_SECRET)\n",
    "        auth.set_access_token(twitter_credentials.ACCESS_TOKEN,\n",
    "                              twitter_credentials.ACCESS_TOKEN_SECRET)\n",
    "        return auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TWITTER ANALYZER\n",
    "Purpose: takes in a tweet and uses TextBlob to determine polarity.\n",
    "Note:\n",
    "(POLARITY > 0)  =====> tweet is positive\n",
    "(POLARITY == 0) =====> tweet is neutral\n",
    "(POLARITY < 0)  =====> tweet is negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterAnalyzer():\n",
    "\n",
    "    # Functionality for analyzing and categorizing content from tweets\n",
    "    def analyze_sentiment(self, tweet):\n",
    "        analysis = TextBlob(tweet)\n",
    "\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 1\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1073914408563167231\n",
      "...396 tweets downloaded so far\n",
      "getting tweets before 1064230822952099840\n",
      "...588 tweets downloaded so far\n",
      "getting tweets before 1047479529810194431\n",
      "...788 tweets downloaded so far\n",
      "getting tweets before 1038992296769777664\n",
      "...988 tweets downloaded so far\n",
      "getting tweets before 990336500058406911\n",
      "...1170 tweets downloaded so far\n",
      "getting tweets before 501492019328745471\n",
      "...1170 tweets downloaded so far\n",
      "DEBUG: Successfully queried to df\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    db = mysql_db()\n",
    "    old_df = db.grab_all_tweets(\"kanyewest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Cleaning\n",
    "First let's take a peak at the data to see how it's looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------General Info & Shape of Dataframe--------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1170 entries, 0 to 1169\n",
      "Data columns (total 3 columns):\n",
      "tweet_id    1170 non-null object\n",
      "date        1170 non-null object\n",
      "tweet       1170 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 27.5+ KB\n",
      "None\n",
      "(1170, 3)\n",
      "--------Head Of Dataframe--------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1080212949464043520</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>One of my favorite of many things about what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080211582955663360</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Spoke with Joe Rogan    Podcast coming soonüî•üî•üî•</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1080209800846176256</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>From now on I‚Äôm performing with my mutherfucki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080206689469489153</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @Maha_Sattva: @kanyewest https://t.co/RDqTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1080206642040340481</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Love everyone      Start the year clean      J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id        date  \\\n",
       "0  1080212949464043520  2019-01-01   \n",
       "1  1080211582955663360  2019-01-01   \n",
       "2  1080209800846176256  2019-01-01   \n",
       "3  1080206689469489153  2019-01-01   \n",
       "4  1080206642040340481  2019-01-01   \n",
       "\n",
       "                                               tweet  \n",
       "0  One of my favorite of many things about what t...  \n",
       "1     Spoke with Joe Rogan    Podcast coming soonüî•üî•üî•  \n",
       "2  From now on I‚Äôm performing with my mutherfucki...  \n",
       "3  RT @Maha_Sattva: @kanyewest https://t.co/RDqTE...  \n",
       "4  Love everyone      Start the year clean      J...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.head()\n",
    "print('--------General Info & Shape of Dataframe--------')\n",
    "print(old_df.info())\n",
    "print(old_df.shape)\n",
    "print('--------Head Of Dataframe--------')\n",
    "old_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Data Cleaning (Sanity Check)\n",
    "I'm going to check the length of each tweet string.\n",
    "Using a box plot I can display the overall distribution of the amount of characters in each tweet.\n",
    "The purpose of this sanity check is to ensure the character count is normal (not above 140 characters).\n",
    "### Sanity Check Results:\n",
    "The box plot shows that the median char count is slightly below 60 and there are are some tweets that are beyond the 140 character max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 299,
       "width": 350
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "old_df['sanity_check_length'] = [len(text) for text in old_df.tweet]\n",
    "figure, axis = plt.subplots(figsize=(5,5))\n",
    "plt.boxplot(old_df.sanity_check_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sanity_check_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>1057232228353273856</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>RT @070Updates: PSA:üö®\\n\\n‚ÄúGHOST TOWN‚Äù @kanyewe...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1057232027995553794</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>RT @KimKardashian: Please check out exclusive ...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1057232012115873792</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>RT @KimKardashian: Watch the full episodes &amp;am...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1056998627737042944</td>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>RT @KimKardashian: #KKWBODY III (UNISEX) is a ...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1056989384438890496</td>\n",
       "      <td>2018-10-29</td>\n",
       "      <td>RT @butsmallhead: Yes hello @kanyewest üëãüéô than...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1045315452753199104</td>\n",
       "      <td>2018-09-27</td>\n",
       "      <td>Dojo\\nA¬†d≈çj≈ç¬†(ÈÅìÂ†¥ &amp;lt;https://t.co/BMDKrR5vzG&amp;g...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>1004430170189467648</td>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>RT @KimKardashian: So grateful to @realDonaldT...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id        date  \\\n",
       "469  1057232228353273856  2018-10-30   \n",
       "470  1057232027995553794  2018-10-30   \n",
       "471  1057232012115873792  2018-10-30   \n",
       "476  1056998627737042944  2018-10-29   \n",
       "477  1056989384438890496  2018-10-29   \n",
       "645  1045315452753199104  2018-09-27   \n",
       "912  1004430170189467648  2018-06-06   \n",
       "\n",
       "                                                 tweet  sanity_check_length  \n",
       "469  RT @070Updates: PSA:üö®\\n\\n‚ÄúGHOST TOWN‚Äù @kanyewe...                  144  \n",
       "470  RT @KimKardashian: Please check out exclusive ...                  144  \n",
       "471  RT @KimKardashian: Watch the full episodes &am...                  144  \n",
       "476  RT @KimKardashian: #KKWBODY III (UNISEX) is a ...                  144  \n",
       "477  RT @butsmallhead: Yes hello @kanyewest üëãüéô than...                  144  \n",
       "645  Dojo\\nA¬†d≈çj≈ç¬†(ÈÅìÂ†¥ &lt;https://t.co/BMDKrR5vzG&g...                  146  \n",
       "912  RT @KimKardashian: So grateful to @realDonaldT...                  147  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_max = old_df[old_df.sanity_check_length > 140]\n",
    "over_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @070Updates: PSA:üö®\n",
      "\n",
      "‚ÄúGHOST TOWN‚Äù @kanyewest feat. @070shake &amp; @partynextdoor \n",
      "\n",
      "is now certified GOLD. üìÄ\n",
      "\n",
      "#070 \n",
      "#YE https://t.co/6DBLusdP‚Ä¶\n",
      "RT @KimKardashian: Please check out exclusive interviews now on https://t.co/HMG1Wp4dJY site! Everyone needs to get out &amp; vote now!  #youar‚Ä¶\n",
      "RT @KimKardashian: Watch the full episodes &amp; more at https://t.co/HMG1Wp4dJY #youareenough #yourvotecounts #bewoke.vote  #empoweryourself h‚Ä¶\n",
      "RT @KimKardashian: #KKWBODY III (UNISEX) is a modern, woody floral opening with Pink &amp; Black Pepper and finishes with layers of creamy Sand‚Ä¶\n",
      "RT @butsmallhead: Yes hello @kanyewest üëãüéô thank much for follow! üëÄ we just want make world laugh &amp; it great to get support from Ye. As rewa‚Ä¶\n",
      "Dojo\n",
      "A¬†d≈çj≈ç¬†(ÈÅìÂ†¥ &lt;https://t.co/BMDKrR5vzG&gt;)¬†is a hall or space for immersive learning or meditation. This is traditi‚Ä¶ https://t.co/Y89keTfn2t\n",
      "RT @KimKardashian: So grateful to @realDonaldTrump, Jared Kushner &amp; to everyone who has showed compassion &amp; contributed countless hours to‚Ä¶\n"
     ]
    }
   ],
   "source": [
    " for i in over_max.tweet:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After printing out the tweets that are beyond 140 char max limit, I can see that the reason for this is because of the special characters (html encoding) that were hidden and added when retweeted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Process\n",
    "### Let's do the following:\n",
    "##### 1) Decode HTML to general text\n",
    "##### 1) Remove URL links (http, www, etc)\n",
    "##### 2) RemoveTwitter handles\n",
    "##### 3) Remove punctuation, speical characters, and numbers\n",
    "##### 4) Make lower case\n",
    "##### 5) Remove stop words\n",
    "##### 6) Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## raw string patterns\n",
    "pat_t_handle = r'@[A-Za-z0-9_]+'\n",
    "pat_url_1 = r'https?://[^ ]+'\n",
    "pat_url_2 = r'www.[^ ]+'\n",
    "pat_RT = r'RT'\n",
    "pat_rt = r'rt'\n",
    "all_patterns = r'|'.join((pat_t_handle, pat_url_1, pat_url_2, pat_RT, pat_rt))\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\",\n",
    "                 \"weren't\":\"were not\",\"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\n",
    "                 \"won't\":\"will not\",\"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\n",
    "                 \"didn't\":\"did not\",\"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\n",
    "                 \"mightn't\":\"might not\",\"mustn't\":\"must not\"}\n",
    "pat_neg = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "#exclude_list = ['RT', 'rt']\n",
    "\n",
    "def tweet_cleaner(dirty_text):\n",
    "    soup = BeautifulSoup(dirty_text, 'lxml')\n",
    "    souped_tweets = soup.get_text()\n",
    "    stripped_tweets = re.sub(all_patterns, '', souped_tweets)\n",
    "    #no_retweets = re.sub(exclude_list, '', stripped_tweets)\n",
    "    lower_case = stripped_tweets.lower()\n",
    "    neg_handled = pat_neg.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    ## creates unnecessary white spaces, During tokenization I'll remove them later\n",
    "    words = [x for x in tok. tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Initiated...\n",
      "Data Cleaning Finished...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## create TwitterAnalyzer instant\n",
    "\n",
    "print (\"Data Cleaning Initiated...\")\n",
    "cleaned_tweets = []\n",
    "## clean tweets\n",
    "for i in range(0,len(old_df)):\n",
    "    cleaned_tweets.append(tweet_cleaner(old_df.tweet[i]))\n",
    "\n",
    "print(\"Data Cleaning Finished...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1080212949464043520</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>One of my favorite of many things about what t...</td>\n",
       "      <td>one of my favorite of many things about what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080211582955663360</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Spoke with Joe Rogan    Podcast coming soonüî•üî•üî•</td>\n",
       "      <td>spoke with joe rogan podcast coming soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1080209800846176256</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>From now on I‚Äôm performing with my mutherfucki...</td>\n",
       "      <td>from now on performing with my mutherfucking h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080206689469489153</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @Maha_Sattva: @kanyewest https://t.co/RDqTE...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1080206642040340481</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Love everyone      Start the year clean      J...</td>\n",
       "      <td>love everyone sta the year clean just be all love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080206417523429376</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @yetaughtni: Honestly felt like the TL need...</td>\n",
       "      <td>honestly felt like the tl needed this words of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1080206353308692480</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @JordanPrileszky: Rolling into 2019 with a ...</td>\n",
       "      <td>rolling into with line up of my favourite illu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1080206247981309952</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @rihsnake: DOPE https://t.co/CcDM9W3h08</td>\n",
       "      <td>dope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1080206155811414016</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @BasedCharlie: Drake telling OVO fest that ...</td>\n",
       "      <td>drake telling ovo fest that kanye is his bigge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1080206130041651200</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @ima_fix_wolves: @kanyewest KANYE KANYE KAN...</td>\n",
       "      <td>kanye kanye kanye wanna frame kids see ghosts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1080206103969914880</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @TrvppyHippy: had to snap real quick ya fee...</td>\n",
       "      <td>had to snap real quick ya feel me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1080205920431296512</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @KanyeStanWV: My two @kanyewest tattoos htt...</td>\n",
       "      <td>my two tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1080205829662371840</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @LUVisUzi: We need a collab Mr West...üòå htt...</td>\n",
       "      <td>we need collab mr west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1080205500854153216</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @tyfg_noodles: @kanyewest my tattoos are a ...</td>\n",
       "      <td>my tattoos are daily inspiration thank you for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1080205153729302528</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @KrysJenner: My new bed spread tho #Famous ...</td>\n",
       "      <td>my new bed spread tho famous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1080204699494535168</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @IconicYeezy: https://t.co/btopYDbxBA</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1080204660462346240</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @CranetheGod: I feel FREEEEE</td>\n",
       "      <td>feel freeeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1080204572717592578</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @YEEZYtaughtyou: @kanyewest the process of ...</td>\n",
       "      <td>the process of greatness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1080204454450712576</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @YEEZYtaughtyou: üêª @TeamKanyeDaily @KimKard...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1080204412436369409</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @traptomcruise22: We are witnessing the gre...</td>\n",
       "      <td>we are witnessing the greatest aist of all tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id        date  \\\n",
       "0   1080212949464043520  2019-01-01   \n",
       "1   1080211582955663360  2019-01-01   \n",
       "2   1080209800846176256  2019-01-01   \n",
       "3   1080206689469489153  2019-01-01   \n",
       "4   1080206642040340481  2019-01-01   \n",
       "5   1080206417523429376  2019-01-01   \n",
       "6   1080206353308692480  2019-01-01   \n",
       "7   1080206247981309952  2019-01-01   \n",
       "8   1080206155811414016  2019-01-01   \n",
       "9   1080206130041651200  2019-01-01   \n",
       "10  1080206103969914880  2019-01-01   \n",
       "11  1080205920431296512  2019-01-01   \n",
       "12  1080205829662371840  2019-01-01   \n",
       "13  1080205500854153216  2019-01-01   \n",
       "14  1080205153729302528  2019-01-01   \n",
       "15  1080204699494535168  2019-01-01   \n",
       "16  1080204660462346240  2019-01-01   \n",
       "17  1080204572717592578  2019-01-01   \n",
       "18  1080204454450712576  2019-01-01   \n",
       "19  1080204412436369409  2019-01-01   \n",
       "\n",
       "                                      original_tweets  \\\n",
       "0   One of my favorite of many things about what t...   \n",
       "1      Spoke with Joe Rogan    Podcast coming soonüî•üî•üî•   \n",
       "2   From now on I‚Äôm performing with my mutherfucki...   \n",
       "3   RT @Maha_Sattva: @kanyewest https://t.co/RDqTE...   \n",
       "4   Love everyone      Start the year clean      J...   \n",
       "5   RT @yetaughtni: Honestly felt like the TL need...   \n",
       "6   RT @JordanPrileszky: Rolling into 2019 with a ...   \n",
       "7          RT @rihsnake: DOPE https://t.co/CcDM9W3h08   \n",
       "8   RT @BasedCharlie: Drake telling OVO fest that ...   \n",
       "9   RT @ima_fix_wolves: @kanyewest KANYE KANYE KAN...   \n",
       "10  RT @TrvppyHippy: had to snap real quick ya fee...   \n",
       "11  RT @KanyeStanWV: My two @kanyewest tattoos htt...   \n",
       "12  RT @LUVisUzi: We need a collab Mr West...üòå htt...   \n",
       "13  RT @tyfg_noodles: @kanyewest my tattoos are a ...   \n",
       "14  RT @KrysJenner: My new bed spread tho #Famous ...   \n",
       "15           RT @IconicYeezy: https://t.co/btopYDbxBA   \n",
       "16                    RT @CranetheGod: I feel FREEEEE   \n",
       "17  RT @YEEZYtaughtyou: @kanyewest the process of ...   \n",
       "18  RT @YEEZYtaughtyou: üêª @TeamKanyeDaily @KimKard...   \n",
       "19  RT @traptomcruise22: We are witnessing the gre...   \n",
       "\n",
       "                                       cleaned_tweets  \n",
       "0   one of my favorite of many things about what t...  \n",
       "1            spoke with joe rogan podcast coming soon  \n",
       "2   from now on performing with my mutherfucking h...  \n",
       "3                                                      \n",
       "4   love everyone sta the year clean just be all love  \n",
       "5   honestly felt like the tl needed this words of...  \n",
       "6   rolling into with line up of my favourite illu...  \n",
       "7                                                dope  \n",
       "8   drake telling ovo fest that kanye is his bigge...  \n",
       "9   kanye kanye kanye wanna frame kids see ghosts ...  \n",
       "10                  had to snap real quick ya feel me  \n",
       "11                                     my two tattoos  \n",
       "12                             we need collab mr west  \n",
       "13  my tattoos are daily inspiration thank you for...  \n",
       "14                       my new bed spread tho famous  \n",
       "15                                                     \n",
       "16                                       feel freeeee  \n",
       "17                           the process of greatness  \n",
       "18                                                     \n",
       "19  we are witnessing the greatest aist of all tim...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(cleaned_tweets,columns=['cleaned_tweets'])\n",
    "\n",
    "old_df['cleaned_tweets'] = [text for text in clean_df.cleaned_tweets]\n",
    "old_df = old_df.drop(['sanity_check_length'], axis='columns')\n",
    "old_df.rename(columns={'tweet':'original_tweets'}, inplace=True)\n",
    "old_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I noticed some cells tweet columns were blank, I comared the \"pre_clean_df\" to \"clean_df\" tweet columns and saw that the blank rows are because they were retweets with no words just a url or video link. So I decided to delete all blank rows before I ran the sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 966 entries, 0 to 1169\n",
      "Data columns (total 4 columns):\n",
      "tweet_id           966 non-null object\n",
      "date               966 non-null object\n",
      "original_tweets    966 non-null object\n",
      "cleaned_tweets     966 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 37.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>original_tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1080212949464043520</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>One of my favorite of many things about what t...</td>\n",
       "      <td>one of my favorite of many things about what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080211582955663360</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Spoke with Joe Rogan    Podcast coming soonüî•üî•üî•</td>\n",
       "      <td>spoke with joe rogan podcast coming soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1080209800846176256</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>From now on I‚Äôm performing with my mutherfucki...</td>\n",
       "      <td>from now on performing with my mutherfucking h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1080206642040340481</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Love everyone      Start the year clean      J...</td>\n",
       "      <td>love everyone sta the year clean just be all love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1080206417523429376</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @yetaughtni: Honestly felt like the TL need...</td>\n",
       "      <td>honestly felt like the tl needed this words of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1080206353308692480</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @JordanPrileszky: Rolling into 2019 with a ...</td>\n",
       "      <td>rolling into with line up of my favourite illu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1080206247981309952</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @rihsnake: DOPE https://t.co/CcDM9W3h08</td>\n",
       "      <td>dope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1080206155811414016</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @BasedCharlie: Drake telling OVO fest that ...</td>\n",
       "      <td>drake telling ovo fest that kanye is his bigge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1080206130041651200</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @ima_fix_wolves: @kanyewest KANYE KANYE KAN...</td>\n",
       "      <td>kanye kanye kanye wanna frame kids see ghosts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1080206103969914880</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @TrvppyHippy: had to snap real quick ya fee...</td>\n",
       "      <td>had to snap real quick ya feel me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1080205920431296512</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @KanyeStanWV: My two @kanyewest tattoos htt...</td>\n",
       "      <td>my two tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1080205829662371840</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @LUVisUzi: We need a collab Mr West...üòå htt...</td>\n",
       "      <td>we need collab mr west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1080205500854153216</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @tyfg_noodles: @kanyewest my tattoos are a ...</td>\n",
       "      <td>my tattoos are daily inspiration thank you for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1080205153729302528</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @KrysJenner: My new bed spread tho #Famous ...</td>\n",
       "      <td>my new bed spread tho famous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1080204660462346240</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @CranetheGod: I feel FREEEEE</td>\n",
       "      <td>feel freeeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1080204572717592578</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @YEEZYtaughtyou: @kanyewest the process of ...</td>\n",
       "      <td>the process of greatness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1080204412436369409</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @traptomcruise22: We are witnessing the gre...</td>\n",
       "      <td>we are witnessing the greatest aist of all tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1080204387522232320</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @noemikardash: 2024 LETS FUCKIN GOOOOO http...</td>\n",
       "      <td>lets fuckin gooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1080204165119336448</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @ima_fix_wolves: @kanyewest THANK YOU FOR H...</td>\n",
       "      <td>thank you for helping reform mental and physic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1080204136497393667</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>RT @ScooptyWhooop: THE UNIVERSE IS ON OUR SIDE</td>\n",
       "      <td>the universe is on our side</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id        date  \\\n",
       "0   1080212949464043520  2019-01-01   \n",
       "1   1080211582955663360  2019-01-01   \n",
       "2   1080209800846176256  2019-01-01   \n",
       "4   1080206642040340481  2019-01-01   \n",
       "5   1080206417523429376  2019-01-01   \n",
       "6   1080206353308692480  2019-01-01   \n",
       "7   1080206247981309952  2019-01-01   \n",
       "8   1080206155811414016  2019-01-01   \n",
       "9   1080206130041651200  2019-01-01   \n",
       "10  1080206103969914880  2019-01-01   \n",
       "11  1080205920431296512  2019-01-01   \n",
       "12  1080205829662371840  2019-01-01   \n",
       "13  1080205500854153216  2019-01-01   \n",
       "14  1080205153729302528  2019-01-01   \n",
       "16  1080204660462346240  2019-01-01   \n",
       "17  1080204572717592578  2019-01-01   \n",
       "19  1080204412436369409  2019-01-01   \n",
       "20  1080204387522232320  2019-01-01   \n",
       "21  1080204165119336448  2019-01-01   \n",
       "22  1080204136497393667  2019-01-01   \n",
       "\n",
       "                                      original_tweets  \\\n",
       "0   One of my favorite of many things about what t...   \n",
       "1      Spoke with Joe Rogan    Podcast coming soonüî•üî•üî•   \n",
       "2   From now on I‚Äôm performing with my mutherfucki...   \n",
       "4   Love everyone      Start the year clean      J...   \n",
       "5   RT @yetaughtni: Honestly felt like the TL need...   \n",
       "6   RT @JordanPrileszky: Rolling into 2019 with a ...   \n",
       "7          RT @rihsnake: DOPE https://t.co/CcDM9W3h08   \n",
       "8   RT @BasedCharlie: Drake telling OVO fest that ...   \n",
       "9   RT @ima_fix_wolves: @kanyewest KANYE KANYE KAN...   \n",
       "10  RT @TrvppyHippy: had to snap real quick ya fee...   \n",
       "11  RT @KanyeStanWV: My two @kanyewest tattoos htt...   \n",
       "12  RT @LUVisUzi: We need a collab Mr West...üòå htt...   \n",
       "13  RT @tyfg_noodles: @kanyewest my tattoos are a ...   \n",
       "14  RT @KrysJenner: My new bed spread tho #Famous ...   \n",
       "16                    RT @CranetheGod: I feel FREEEEE   \n",
       "17  RT @YEEZYtaughtyou: @kanyewest the process of ...   \n",
       "19  RT @traptomcruise22: We are witnessing the gre...   \n",
       "20  RT @noemikardash: 2024 LETS FUCKIN GOOOOO http...   \n",
       "21  RT @ima_fix_wolves: @kanyewest THANK YOU FOR H...   \n",
       "22     RT @ScooptyWhooop: THE UNIVERSE IS ON OUR SIDE   \n",
       "\n",
       "                                       cleaned_tweets  \n",
       "0   one of my favorite of many things about what t...  \n",
       "1            spoke with joe rogan podcast coming soon  \n",
       "2   from now on performing with my mutherfucking h...  \n",
       "4   love everyone sta the year clean just be all love  \n",
       "5   honestly felt like the tl needed this words of...  \n",
       "6   rolling into with line up of my favourite illu...  \n",
       "7                                                dope  \n",
       "8   drake telling ovo fest that kanye is his bigge...  \n",
       "9   kanye kanye kanye wanna frame kids see ghosts ...  \n",
       "10                  had to snap real quick ya feel me  \n",
       "11                                     my two tattoos  \n",
       "12                             we need collab mr west  \n",
       "13  my tattoos are daily inspiration thank you for...  \n",
       "14                       my new bed spread tho famous  \n",
       "16                                       feel freeeee  \n",
       "17                           the process of greatness  \n",
       "19  we are witnessing the greatest aist of all tim...  \n",
       "20                                 lets fuckin gooooo  \n",
       "21  thank you for helping reform mental and physic...  \n",
       "22                        the universe is on our side  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_index = old_df[old_df.cleaned_tweets == ''].index.tolist()\n",
    "old_df.drop(zeros_index, inplace=True)\n",
    "print(old_df.info())\n",
    "old_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "4    1\n",
      "5    1\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "analyzer = TwitterAnalyzer()\n",
    "old_df['sentiment'] = np.array([analyzer.analyze_sentiment(x) for x in old_df['cleaned_tweets']])\n",
    "print(old_df['sentiment'].head())\n",
    "old_df.to_csv(\"cleaned_kanye_tweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
